pivot_longer(-Exited)
ggplot(histgram.num, aes(x=value, fill=Exited)) +
geom_histogram() +
facet_wrap(facets = ~name, scales = "free") +
theme_bw()
histgram.cat <- data %>%
select(Geography, Gender, HasCrCard, IsActiveMember, Exited) %>%
pivot_longer(-Exited)
ggplot(histgram.cat, aes(x=value, fill=Exited)) +
geom_bar() +
facet_wrap(facets = ~name, scales = "free") +
theme_bw()
bar.cat <- data %>%
select(Geography, Gender, HasCrCard, IsActiveMember, Exited) %>%
pivot_longer(-Exited)
ggplot(bar.cat, aes(x=value, fill=Exited)) +
geom_bar() +
facet_wrap(facets = ~name, scales = "free") +
theme_bw()
m0 <- glm(Exited ~ log(CreditScore) + Gender + Age + log(Balance) + NumOfProducts + IsActiveMember + Geography + Tenure + HasCrCard + log(EstimatedSalary), data = train, family = "binomial")
m0 <- glm(Exited ~ CreditScore + Gender + Age + Balance + NumOfProducts + IsActiveMember + Geography + Tenure + HasCrCard + EstimatedSalary, data = train, family = "binomial")
m0s <- step(m0, direction = "backward", trace = F)
summary(m0s)
anova(m0s, test = "Chisq")
m0s.pred <- predict(m0s, test, type = "response")
m0s.pred.labels <- ifelse(m0s.pred > 0.5, 1, 0) %>%
as.factor()
confusionMatrix(m0s.pred.labels, test$Exited)
137/(137+474)
# report odds ratios
exp(cbind(OR = coef(m0s), confint(m0s)))
boxplot <- data %>%
select_if(is.numeric) %>%
pivot_longer(everything())
ggplot(boxplot, aes(x=name, y=value, fill=name)) +
geom_boxplot() +
facet_wrap(facets = ~name, scales = "free") +
theme_bw()
m1 <- naiveBayes(Exited ~ CreditScore + Geography + Gender + Age + Tenure + Balance + HasCrCard + IsActiveMember + EstimatedSalary, data = train)
m1.pred <- predict(m1, test)
confusionMatrix(m1.pred, test$Exited)
boxcox(m1, lambda = seq(-0.25, 0.75, by = 0.05), plotit = TRUE)
# set up tuning grid
m1.tuning <- expand.grid(usekernel = c(T,F))
View(m1.tuning)
m1.tune <- train(
x = x,
y = y,
method = "nb",
trControl = train
)
x <- data %>%
select(CreditScore, Geography, Gender, Age, Tenure, Balance, HasCrCard, IsActiveMember, EstimatedSalary)
y <- data$Exited
m1.tune <- train(
x = x,
y = y,
method = "nb",
trControl = train
)
install.packages(c("Amelia", "AMR", "antiword", "anytime", "arm", "backports", "bayesplot", "bayestestR", "betareg", "BH", "bit64", "BMisc", "Boom", "BoomSpikeSlab", "brew", "brio", "broom", "bsts", "Cairo", "callr", "car", "carData", "CausalImpact", "checkpoint", "class", "clipr", "clue", "cobalt", "coefplot", "colorspace", "commonmark", "corrplot", "cowplot", "cpp11", "crayon", "credentials", "crosstalk", "cubature", "datawizard", "DBI", "dbplyr", "dcurver", "DeclareDesign", "dendextend", "DEoptimR", "desc", "devtools", "did", "diffobj", "doParallel", "dplyr", "DT", "dtw", "e1071", "effects", "effectsize", "emmeans", "ergm", "ergm.count", "estimatr", "evaluate", "ExPanDaR", "expm", "fabricatr", "FactoMineR", "fansi", "fields", "flextable", "foreach", "forecast", "forecastHybrid", "formattable", "fpc", "fs", "gdtools", "geepack", "geojsonsf", "gert", "GGally", "gganimate", "ggdag", "ggeffects", "ggforce", "ggfortify", "gghighlight", "ggiraph", "ggiraphExtra", "ggpubr", "ggraph", "ggrepel", "ggsignif", "ggthemes", "ggvis", "gh", "git2r", "glmmTMB", "goftest", "gower", "graphlayouts", "greybox", "gsynth", "hexbin", "Hmisc", "hms", "htmlTable", "hts", "httpuv", "hunspell", "igraph", "infer", "insight", "ISOcodes", "iterators", "JavaGD", "JGR", "jomo", "jsonify", "knitr", "lamW", "later", "lava", "lavaan", "leaflet", "lfe", "lme4", "lmtest", "loo", "ltm", "lubridate", "lwgeom", "magick", "magrittr", "manipulateWidget", "mapproj", "maptools", "MASS", "Matching", "MatchIt", "Matrix", "maxLik", "mclust", "memoise", "mice", "miceadds", "modelr", "moonBook", "msm", "multcomp", "mvnfast", "mvtnorm", "naniar", "network", "networkDynamic", "nlme", "nloptr", "nnet", "nsyllable", "officer", "openssl", "openxlsx", "optimx", "osqp", "pander", "panelView", "parameters", "patchwork", "pbkrtest", "pbv", "pcalg", "pdftools", "performance", "permute", "pkgload", "PKI", "plm", "plotly", "plyr", "polycor", "posterior", "pracma", "pROC", "processx", "progressr", "promises", "proxyC", "psych", "qualV", "quanteda", "quantmod", "quantreg", "randomizr", "raster", "rbibutils", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "RCurl", "Rdpack", "rdrobust", "readODS", "readr", "readstata13", "remotes", "reprex", "reticulate", "rgdal", "rgeos", "rgl", "rio", "rlang", "rlist", "rmarkdown", "robustbase", "roxygen2", "rpart", "rstan", "Rttf2pt1", "rvest", "s2", "sandwich", "sass", "satellite", "seasonal", "servr", "sessioninfo", "sf", "sfheaders", "shiny", "shinycssloaders", "shinystan", "simstudy", "sirt", "sjlabelled", "sjmisc", "sjstats", "slam", "smooth", "sna", "sp", "spam", "spatial", "spData", "stargazer", "statnet", "statnet.common", "stm", "stopwords", "stringi", "striprtf", "survival", "svglite", "sys", "systemfonts", "TAM", "tergm", "terra", "testthat", "texreg", "textdata", "TH.data", "tictoc", "tidycensus", "tidygraph", "tidyr", "tidytext", "tidyverse", "tigris", "tinytex", "tm", "tmap", "tmaptools", "TMB", "tseries", "tsibble", "tsna", "TTR", "tweenr", "units", "UScensus2010", "usethis", "utf8", "uuid", "vcd", "vegan", "VGAM", "visreg", "vroom", "WhatIf", "withr", "x13binary", "xaringan", "xfun", "xlsx", "xml2", "xts", "yaml", "zip", "zoo", "ztable"))
install.packages(c("Amelia", "AMR", "antiword", "anytime", "arm", "backports", "bayesplot", "bayestestR", "betareg", "BH", "bit64", "BMisc", "Boom", "BoomSpikeSlab", "brew", "brio", "broom", "bsts", "Cairo", "callr", "car", "carData", "CausalImpact", "checkpoint", "class", "clipr", "clue", "cobalt", "coefplot", "colorspace", "commonmark", "corrplot", "cowplot", "cpp11", "crayon", "credentials", "crosstalk", "cubature", "datawizard", "DBI", "dbplyr", "dcurver", "DeclareDesign", "dendextend", "DEoptimR", "desc", "devtools", "did", "diffobj", "doParallel", "dplyr", "DT", "dtw", "e1071", "effects", "effectsize", "emmeans", "ergm", "ergm.count", "estimatr", "evaluate", "ExPanDaR", "expm", "fabricatr", "FactoMineR", "fansi", "fields", "flextable", "foreach", "forecast", "forecastHybrid", "formattable", "fpc", "fs", "gdtools", "geepack", "geojsonsf", "gert", "GGally", "gganimate", "ggdag", "ggeffects", "ggforce", "ggfortify", "gghighlight", "ggiraph", "ggiraphExtra", "ggpubr", "ggraph", "ggrepel", "ggsignif", "ggthemes", "ggvis", "gh", "git2r", "glmmTMB", "goftest", "gower", "graphlayouts", "greybox", "gsynth", "hexbin", "Hmisc", "hms", "htmlTable", "hts", "httpuv", "hunspell", "igraph", "infer", "insight", "ISOcodes", "iterators", "JavaGD", "JGR", "jomo", "jsonify", "knitr", "lamW", "later", "lava", "lavaan", "leaflet", "lfe", "lme4", "lmtest", "loo", "ltm", "lubridate", "lwgeom", "magick", "magrittr", "manipulateWidget", "mapproj", "maptools", "MASS", "Matching", "MatchIt", "Matrix", "maxLik", "mclust", "memoise", "mice", "miceadds", "modelr", "moonBook", "msm", "multcomp", "mvnfast", "mvtnorm", "naniar", "network", "networkDynamic", "nlme", "nloptr", "nnet", "nsyllable", "officer", "openssl", "openxlsx", "optimx", "osqp", "pander", "panelView", "parameters", "patchwork", "pbkrtest", "pbv", "pcalg", "pdftools", "performance", "permute", "pkgload", "PKI", "plm", "plotly", "plyr", "polycor", "posterior", "pracma", "pROC", "processx", "progressr", "promises", "proxyC", "psych", "qualV", "quanteda", "quantmod", "quantreg", "randomizr", "raster", "rbibutils", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "RCurl", "Rdpack", "rdrobust", "readODS", "readr", "readstata13", "remotes", "reprex", "reticulate", "rgdal", "rgeos", "rgl", "rio", "rlang", "rlist", "rmarkdown", "robustbase", "roxygen2", "rpart", "rstan", "Rttf2pt1", "rvest", "s2", "sandwich", "sass", "satellite", "seasonal", "servr", "sessioninfo", "sf", "sfheaders", "shiny", "shinycssloaders", "shinystan", "simstudy", "sirt", "sjlabelled", "sjmisc", "sjstats", "slam", "smooth", "sna", "sp", "spam", "spatial", "spData", "stargazer", "statnet", "statnet.common", "stm", "stopwords", "stringi", "striprtf", "survival", "svglite", "sys", "systemfonts", "TAM", "tergm", "terra", "testthat", "texreg", "textdata", "TH.data", "tictoc", "tidycensus", "tidygraph", "tidyr", "tidytext", "tidyverse", "tigris", "tinytex", "tm", "tmap", "tmaptools", "TMB", "tseries", "tsibble", "tsna", "TTR", "tweenr", "units", "UScensus2010", "usethis", "utf8", "uuid", "vcd", "vegan", "VGAM", "visreg", "vroom", "WhatIf", "withr", "x13binary", "xaringan", "xfun", "xlsx", "xml2", "xts", "yaml", "zip", "zoo", "ztable"))
install.packages(c("Amelia", "AMR", "antiword", "anytime", "arm", "backports", "bayesplot", "bayestestR", "betareg", "BH", "bit64", "BMisc", "Boom", "BoomSpikeSlab", "brew", "brio", "broom", "bsts", "Cairo", "callr", "car", "carData", "CausalImpact", "checkpoint", "class", "clipr", "clue", "cobalt", "coefplot", "colorspace", "commonmark", "corrplot", "cowplot", "cpp11", "crayon", "credentials", "crosstalk", "cubature", "datawizard", "DBI", "dbplyr", "dcurver", "DeclareDesign", "dendextend", "DEoptimR", "desc", "devtools", "did", "diffobj", "doParallel", "dplyr", "DT", "dtw", "e1071", "effects", "effectsize", "emmeans", "ergm", "ergm.count", "estimatr", "evaluate", "ExPanDaR", "expm", "fabricatr", "FactoMineR", "fansi", "fields", "flextable", "foreach", "forecast", "forecastHybrid", "formattable", "fpc", "fs", "gdtools", "geepack", "geojsonsf", "gert", "GGally", "gganimate", "ggdag", "ggeffects", "ggforce", "ggfortify", "gghighlight", "ggiraph", "ggiraphExtra", "ggpubr", "ggraph", "ggrepel", "ggsignif", "ggthemes", "ggvis", "gh", "git2r", "glmmTMB", "goftest", "gower", "graphlayouts", "greybox", "gsynth", "hexbin", "Hmisc", "hms", "htmlTable", "hts", "httpuv", "hunspell", "igraph", "infer", "insight", "ISOcodes", "iterators", "JavaGD", "JGR", "jomo", "jsonify", "knitr", "lamW", "later", "lava", "lavaan", "leaflet", "lfe", "lme4", "lmtest", "loo", "ltm", "lubridate", "lwgeom", "magick", "magrittr", "manipulateWidget", "mapproj", "maptools", "MASS", "Matching", "MatchIt", "Matrix", "maxLik", "mclust", "memoise", "mice", "miceadds", "modelr", "moonBook", "msm", "multcomp", "mvnfast", "mvtnorm", "naniar", "network", "networkDynamic", "nlme", "nloptr", "nnet", "nsyllable", "officer", "openssl", "openxlsx", "optimx", "osqp", "pander", "panelView", "parameters", "patchwork", "pbkrtest", "pbv", "pcalg", "pdftools", "performance", "permute", "pkgload", "PKI", "plm", "plotly", "plyr", "polycor", "posterior", "pracma", "pROC", "processx", "progressr", "promises", "proxyC", "psych", "qualV", "quanteda", "quantmod", "quantreg", "randomizr", "raster", "rbibutils", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "RCurl", "Rdpack", "rdrobust", "readODS", "readr", "readstata13", "remotes", "reprex", "reticulate", "rgdal", "rgeos", "rgl", "rio", "rlang", "rlist", "rmarkdown", "robustbase", "roxygen2", "rpart", "rstan", "Rttf2pt1", "rvest", "s2", "sandwich", "sass", "satellite", "seasonal", "servr", "sessioninfo", "sf", "sfheaders", "shiny", "shinycssloaders", "shinystan", "simstudy", "sirt", "sjlabelled", "sjmisc", "sjstats", "slam", "smooth", "sna", "sp", "spam", "spatial", "spData", "stargazer", "statnet", "statnet.common", "stm", "stopwords", "stringi", "striprtf", "survival", "svglite", "sys", "systemfonts", "TAM", "tergm", "terra", "testthat", "texreg", "textdata", "TH.data", "tictoc", "tidycensus", "tidygraph", "tidyr", "tidytext", "tidyverse", "tigris", "tinytex", "tm", "tmap", "tmaptools", "TMB", "tseries", "tsibble", "tsna", "TTR", "tweenr", "units", "UScensus2010", "usethis", "utf8", "uuid", "vcd", "vegan", "VGAM", "visreg", "vroom", "WhatIf", "withr", "x13binary", "xaringan", "xfun", "xlsx", "xml2", "xts", "yaml", "zip", "zoo", "ztable"))
install.packages(c("Amelia", "AMR", "antiword", "anytime", "arm", "backports", "bayesplot", "bayestestR", "betareg", "BH", "bit64", "BMisc", "Boom", "BoomSpikeSlab", "brew", "brio", "broom", "bsts", "Cairo", "callr", "car", "carData", "CausalImpact", "checkpoint", "class", "clipr", "clue", "cobalt", "coefplot", "colorspace", "commonmark", "corrplot", "cowplot", "cpp11", "crayon", "credentials", "crosstalk", "cubature", "datawizard", "DBI", "dbplyr", "dcurver", "DeclareDesign", "dendextend", "DEoptimR", "desc", "devtools", "did", "diffobj", "doParallel", "dplyr", "DT", "dtw", "e1071", "effects", "effectsize", "emmeans", "ergm", "ergm.count", "estimatr", "evaluate", "ExPanDaR", "expm", "fabricatr", "FactoMineR", "fansi", "fields", "flextable", "foreach", "forecast", "forecastHybrid", "formattable", "fpc", "fs", "gdtools", "geepack", "geojsonsf", "gert", "GGally", "gganimate", "ggdag", "ggeffects", "ggforce", "ggfortify", "gghighlight", "ggiraph", "ggiraphExtra", "ggpubr", "ggraph", "ggrepel", "ggsignif", "ggthemes", "ggvis", "gh", "git2r", "glmmTMB", "goftest", "gower", "graphlayouts", "greybox", "gsynth", "hexbin", "Hmisc", "hms", "htmlTable", "hts", "httpuv", "hunspell", "igraph", "infer", "insight", "ISOcodes", "iterators", "JavaGD", "JGR", "jomo", "jsonify", "knitr", "lamW", "later", "lava", "lavaan", "leaflet", "lfe", "lme4", "lmtest", "loo", "ltm", "lubridate", "lwgeom", "magick", "magrittr", "manipulateWidget", "mapproj", "maptools", "MASS", "Matching", "MatchIt", "Matrix", "maxLik", "mclust", "memoise", "mice", "miceadds", "modelr", "moonBook", "msm", "multcomp", "mvnfast", "mvtnorm", "naniar", "network", "networkDynamic", "nlme", "nloptr", "nnet", "nsyllable", "officer", "openssl", "openxlsx", "optimx", "osqp", "pander", "panelView", "parameters", "patchwork", "pbkrtest", "pbv", "pcalg", "pdftools", "performance", "permute", "pkgload", "PKI", "plm", "plotly", "plyr", "polycor", "posterior", "pracma", "pROC", "processx", "progressr", "promises", "proxyC", "psych", "qualV", "quanteda", "quantmod", "quantreg", "randomizr", "raster", "rbibutils", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "RCurl", "Rdpack", "rdrobust", "readODS", "readr", "readstata13", "remotes", "reprex", "reticulate", "rgdal", "rgeos", "rgl", "rio", "rlang", "rlist", "rmarkdown", "robustbase", "roxygen2", "rpart", "rstan", "Rttf2pt1", "rvest", "s2", "sandwich", "sass", "satellite", "seasonal", "servr", "sessioninfo", "sf", "sfheaders", "shiny", "shinycssloaders", "shinystan", "simstudy", "sirt", "sjlabelled", "sjmisc", "sjstats", "slam", "smooth", "sna", "sp", "spam", "spatial", "spData", "stargazer", "statnet", "statnet.common", "stm", "stopwords", "stringi", "striprtf", "survival", "svglite", "sys", "systemfonts", "TAM", "tergm", "terra", "testthat", "texreg", "textdata", "TH.data", "tictoc", "tidycensus", "tidygraph", "tidyr", "tidytext", "tidyverse", "tigris", "tinytex", "tm", "tmap", "tmaptools", "TMB", "tseries", "tsibble", "tsna", "TTR", "tweenr", "units", "UScensus2010", "usethis", "utf8", "uuid", "vcd", "vegan", "VGAM", "visreg", "vroom", "WhatIf", "withr", "x13binary", "xaringan", "xfun", "xlsx", "xml2", "xts", "yaml", "zip", "zoo", "ztable"))
m1.tune <- train(
x = x,
y = y,
method = "nb",
trControl = train
)
library(caret)
m1.tune <- train(
x = x,
y = y,
method = "nb",
trControl = train
)
install.packages("klaR")
m1.tune <- train(
x = x,
y = y,
method = "nb",
trControl = train
)
library(caret)
library(psych)
library(MASS)
library(kableExtra)
library(kableExtra)
library(psych)
library(MASS)
library(kableExtra)
library(psych)
library(MASS)
#library(kableExtra)
library(class)
library(caret)
library(psych)
library(MASS)
library(kableExtra)
library(class)
library(caret)
library(e1071)
library(naivebayes)
library(ggplot2)
library(GGally)
library(tidyverse)
data <- read.csv("Churn_Modeling.csv", stringsAsFactors = F)
# generate summary statistics for numeric variables
data %>%
summarise_all(funs(sum(is.na(.))))
data <- data %>%
mutate(HasCrCard = as.factor(HasCrCard),
IsActiveMember = as.factor(IsActiveMember),
Exited = as.factor(Exited),
RowNumber = as.character(RowNumber),
CustomerId = as.character(CustomerId))
summary.statistics <- data %>%
select_if(is.numeric) %>%
describe() %>%
select(-c(vars,mad,trimmed,median,range,skew,kurtosis))
kable(summary.statistics) %>%
kable_styling(latex_options = "scale_down")
set.seed(123)
partition <- createDataPartition(y = data$Exited,
p=0.7,
list = F)
train <- data[partition,]
test <- data[-partition,]
# create standardized datasets for KNN
train.sd <- train %>%
select_if(is.numeric, scale)
# create standardized datasets for KNN
train.sd <- train %>%
select_if(is.numeric) %>%
scale()
test.sd <- test %>%
select_if(is.numeric) %>%
scale()
train.y <- data$Exited[partition]
test.y <- data$Exited[-partition]
m2 <- knn(train.sd, test.sd, train.y, k=1)
mean(test.y != m2)
mean(test.y != 0)
errors <- rep(NA, 9)
for (i in 1:9) {
knn.mod <- knn(train.sd, test.sd, train.y, k=i)
errors[i] <- mean(test.y != knn.mod)
}
ggplot(errors) +
geom_line()
plot(errors)
errors <- rep(NA, 10)
for (i in 1:10) {
knn.mod <- knn(train.sd, test.sd, train.y, k=i)
errors[i] <- mean(test.y != knn.mod)
}
errors
m2 <- knn(train.sd, test.sd, train.y, k=6)
mean(test.y != m2)
mean(test.y != 0)
mean(test.y == m2)
mean(test.y == 0)
errors <- rep(NA, 10)
for (i in 1:10) {
knn.mod <- knn(train.sd, test.sd, train.y, k=i)
errors[i] <- mean(test.y == knn.mod)
}
m1 <- naiveBayes(Exited ~ CreditScore + Geography + Gender + Age + Tenure + Balance + HasCrCard + IsActiveMember + EstimatedSalary, data = train)
m1.pred <- predict(m1, test)
confusionMatrix(m1.pred, test$Exited)
144/(144+467)
467/(144+467)
confusionMatrix(m1.pred, test$Exited)
2310/(2310+467)
m0 <- glm(Exited ~ CreditScore + Gender + Age + Balance + NumOfProducts + IsActiveMember + Geography + Tenure + HasCrCard + EstimatedSalary, data = train, family = "binomial")
m0s <- step(m0, direction = "backward", trace = F)
summary(m0s)
anova(m0s, test = "Chisq")
m0s.pred <- predict(m0s, test, type = "response")
m0s.pred.labels <- ifelse(m0s.pred > 0.5, 1, 0) %>%
as.factor()
confusionMatrix(m0s.pred.labels, test$Exited)
2318/(2318+70)
confusionMatrix(m0s.pred.labels, test$Exited)
472/(472+139)
472/(472+139)
confusionMatrix(m0s.pred.labels, test$Exited)
2318+70/2999
(2318+70)/2999
confusionMatrix(m0s.pred.labels, test$Exited)
(139+472)/2999 # null error rate
confusionMatrix(m0s.pred.labels, test$Exited)
m1 <- naiveBayes(Exited ~ CreditScore + Geography + Gender + Age + Tenure + Balance + HasCrCard + IsActiveMember + EstimatedSalary, data = train)
m1.pred <- predict(m1, test)
confusionMatrix(m1.pred, test$Exited)
2310/(2310+467)
(467+144)/2999
confusionMatrix(m1.pred, test$Exited)
144/(144+467)
confusionMatrix(m1.pred, test$Exited)
144/(144+467)
confusionMatrix(m0s.pred.labels, test$Exited)
(139+472)/2999 # null error rate
confusionMatrix(m1.pred, test$Exited)
(467+144)/2999
m2 <- knn(train.sd, test.sd, train.y, k=6)
mean(test.y == m2)
mean(test.y == 0)
acc <- rep(NA, 10)
spc <- rep(NA, 10)
for (i in 1:10) {
knn.mod <- knn(train.sd, test.sd, train.y, k=i)
acc[i] <- mean(test.y == knn.mod)
spc[i] <- mean(test.y == knn.mod & test.y == 1)
}
kable(cbind(acc,spc))
acc <- rep(NA, 10)
spc <- rep(NA, 10)
for (i in 1:10) {
knn.mod <- knn(train.sd, test.sd, train.y, k=i)
acc[i] <- mean(test.y == knn.mod)
spc[i] <- length(which((test.y == knn.mod) & (test.y==1)))/length(which(test.y==1))
}
kable(cbind(acc,spc))
kable(cbind(acc,spc,1:6))
kable(cbind(acc,spc,1:10))
acc <- rep(NA, 10)
spc <- rep(NA, 10)
index <- 1:10
for (i in index) {
knn.mod <- knn(train.sd, test.sd, train.y, k=i)
acc[i] <- mean(test.y == knn.mod)
spc[i] <- length(which((test.y == knn.mod) & (test.y==1)))/length(which(test.y==1))
}
kable(cbind(acc,spc,index))
64/100*36/100
x <- 1:10
y <- 11:30
xc <- x - mean(x)
yc <- y - mean(y)
(1-(10-1))*t(xc)%*%yc
(1/(10-1))*t(xc)%*%yc
x <- 1:10
y <- 11:20
xc <- x - mean(x)
yc <- y - mean(y)
(1/(10-1))*t(xc)%*%yc
cov(x,y)
x <- 1:10
y <- 11:20
xc <- x - mean(x)
yc <- y - mean(y)
(1/(10-1))*t(xc)%*%xc
var(x)
setwd("D:/Data_Science/experimental-design/ab-testing/customer-analytics")
data <- read_csv("purchase_data_v1.csv")
data <- read.csv("purchase_data_v1.csv", stringsAsFactors = F)
purchase <- read.csv("purchase_data_v1.csv", stringsAsFactors = F)
rm(data)
demographics <- read.csv("user_demographics_paywall.csv", stringsAsFactors = F)
library(tidyverse)
library(tidyverse)
purchase <- read.csv("purchase_data_v1.csv", stringsAsFactors = F)
demographics <- read.csv("user_demographics_paywall.csv", stringsAsFactors = F)
purchase <- purchase %>%
left_join(demographics, by = "uid")
mean(purchase$price)
purchase <- purchase %>%
left_join(demographics, by = "uid") %>%
group_by(uid) %>%
summarise(mean = mean(price)) %>%
ungroup()
library(tidyverse)
purchase <- read.csv("purchase_data_v1.csv", stringsAsFactors = F)
demographics <- read.csv("user_demographics_v1.csv", stringsAsFactors = F)
purchase <- purchase %>%
left_join(demographics, by = "uid") %>%
group_by(uid) %>%
summarise(mean = mean(price)) %>%
ungroup()
customer_data <- read.csv("user_demographics_v1.csv", stringsAsFactors = F)
purchase_data <- read.csv("purchase_data_v1.csv", stringsAsFactors = F)
rm(purchase)
rm(demographics)
purchase_data <- purchase_data %>%
left_join(customer_data)
library(tidyverse)
customer_data <- read.csv("user_demographics_v1.csv", stringsAsFactors = F)
purchase_data <- read.csv("purchase_data_v1.csv", stringsAsFactors = F)
purchase_data_summary <- purchase_data %>%
left_join(customer_data) %>%
group_by(country, device) %>%
summarise(price = mean(price),
age = mean(age)) %>%
ungroup()
purchase_data_summary <- purchase_data %>%
left_join(customer_data) %>%
group_by(country, device) %>%
summarise(price = mean(price),
age = mean(age)) %>%
ungroup()
mean(purchase_data_summary$price)
purchase_data_summary <- purchase_data %>%
left_join(customer_data)
purchase_data_summary <- purchase_data %>%
inner_join(customer_data)
purchase_data_summary <- purchase_data %>%
inner_join(customer_data) %>%
group_by(country, device) %>%
summarise(price = mean(price),
age = mean(age)) %>%
ungroup()
mean(purchase_data_summary$price)
View(purchase_data_summary)
purchase_data_summary <- purchase_data %>%
inner_join(customer_data)
purchase_data_summary <- purchase_data %>%
inner_join(customer_data, by = "uid")
current_date <- as.Date("2018-03-17")
max_purchase_date <- current_date - 28
purchase_data_summary$date <- as.Date(purchase_data_summary$date)
purchase_data_summary$reg_date <- as.Date(purchase_data_summary$reg_date)
purchase_data_subgroup <- purchase_data_summary %>%
filter(reg_date < max_purchase_date)
mean(purchase_data_subgroup$price)
library(tidyverse)
customer <- read.csv("user_demographics_v1.csv", stringsAsFactors = F)
purchase <- read.csv("purchase_data_v1.csv", stringsAsFactors = F)
revenue <- read.csv("daily_revenue.csv", stringsAsFactors = F)
paywall <- read.csv("user_demographics_paywall.csv", stringsAsFactors = F)
abtesting <- read.csv("AB_testing_exercise.csv", stringsAsFactors = F)
purchase <- purchase %>%
inner_join(customer, by = "uid")
purchase %>%
group_by(gender, device) %>%
summarise(mean.price = mean(price),
median.price = median(price)) %>%
ungroup() %>%
as_tibble()
purchase %>%
group_by(gender, device) %>%
summarise(mean.price = mean(price),
median.price = median(price)) %>%
ungroup() %>%
as_tibble()
library(kableExtra)
purchase %>%
group_by(gender, device) %>%
summarise(mean.price = mean(price),
median.price = median(price)) %>%
ungroup() %>%
kable()
purchase %>%
group_by(gender, device) %>%
summarise(mean.price = mean(price),
median.price = median(price)) %>%
ungroup() %>%
kable(col.names = c("Gender","Device","Mean","Median"))
current_date <- as.Date("2018-03-17")
max_purchase_date <- current_date - 28
# filter to users who registered before our max date
purchase$reg_date <- as.Date(purchase$reg_date)
purchase$reg_date <- as.Date(purchase$reg_date)
purchase_conversion <- purchase %>%
#filter(reg_date < max_purchase_date) %>%
filter(date <= reg_date+28)
mean(purchase_conversion$price)
purchase_conversion <- purchase %>%
filter(reg_date < max_purchase_date) %>%
filter(date <= reg_date+28)
mean(purchase_conversion$price)
# average purchase by cohort
max_reg_date <- current_date - 28
# compute KPI
current_date <- as.Date("2018-03-17")
max_purchase_date <- current_date - 28
# filter to purchases within the first 28 days of registration (convert within a month)
purchase$reg_date <- as.Date(purchase$reg_date)
purchase$date <- as.Date(purchase$date)
purchase_conversion <- purchase %>%
filter(reg_date < max_purchase_date) %>%
filter(date <= reg_date+28)
mean(purchase_conversion$price)
# average purchase by cohort
max_reg_date <- current_date - 28
purchase_group <- purchase %>%
filter(reg_date < max_reg_date) %>%
filter(date < reg_date + 28) %>%
group_by(gender, device) %>%
summarise(mean.price = mean(price),
median.price = median(price)) %>%
ungroup() %>%
kable(col.names = c("Gender","device","Mean","Median"))
purchase_group
revenue$date <- as.Date(revenue$date)
ggplot(revenue, aes(x=date, y=revenue)) +
geom_line()
revenue %>%
group_by(date) %>%
summarise(sum.revenue = sum(revenue)) +
ggplot(aes(x=date,y=sum.revenue)) +
geom_line()
revenue_daily <- revenue %>%
group_by(date) %>%
summarise(sum.revenue = sum(revenue))
ggplot(revenue_daily, aes(x=date,y=sum.revenue)) +
geom_line()
ggplot(revenue_daily, aes(x=date,y=sum.revenue)) +
geom_line() +
theme_bw()
ggplot(revenue_daily, aes(x=date,y=sum.revenue)) +
geom_line() +
theme_bw() +
labs(x="Date",y="Revenue")
install.packages("geofacet")
install.packages("zoo")
library(zoo)
revenue_daily <- revenue_daily %>%
mutate(week = rollmean(sum.revenue, k=7, fill = NA),
month = rollmean(sum.revenue, k=28, fill = NA),
year = rollmean(sum.revenue, k=365, fill = NA))
revenue_compare <- revenue_daily %>%
pivot_longer(names_to = "rolling_mean_key",
values_to = "rolling_mean_value",
cols = c(week, month, year))
ggplot(revenue_compare, aes(x=date,
y = rolling_mean_value,
color = rolling_mean_key)) +
geom_line()
ggplot(revenue_compare, aes(x=date,
y = rolling_mean_value,
color = rolling_mean_key)) +
geom_line() +
theme_bw() +
guides(x = "R")
ggplot(revenue_compare, aes(x=date,
y = rolling_mean_value,
color = rolling_mean_key)) +
geom_line() +
theme_bw() +
guide_legend(x = "Moving Average")
ggplot(revenue_compare, aes(x=date,
y = rolling_mean_value,
color = rolling_mean_key)) +
geom_line() +
theme_bw() +
labs(x="Date", y="Revenue") +
guides(guide_legend(title = "Moving Average"))
ggplot(revenue_compare, aes(x=date,
y = rolling_mean_value,
color = rolling_mean_key)) +
geom_line() +
theme_bw() +
labs(x="Date", y="Revenue") +
scale_fill_discrete(name = "Moving Average")
ggplot(revenue_compare, aes(x=date,
y = rolling_mean_value,
color = rolling_mean_key)) +
geom_line() +
theme_bw() +
labs(x="Date", y="Revenue") +
scale_color_discrete(name = "Moving Average")
install.packages("pracma")
library(pracma)
# choose the span
revenue_daily <- revenue_daily %>%
mutate(small = movavg(sum.revenue, 10, type = "e"),
medium = movavg(sum.revenue, 100, type = "e"),
large = movavg(sum.revenue, 500, type = "e"))
era_compare <- revenue_daily %>%
pivot_longer(names_to = "era_key",
values_to = "era_value",
cols = c(small, medium, large))
ggplot(revenue_compare, aes(x=date,
y = era_value,
color = era_key)) +
geom_line() +
theme_bw() +
labs(x="Date", y="Revenue") +
scale_color_discrete(name = "Exponential Rolling Average")
era_compare <- revenue_daily %>%
pivot_longer(names_to = "era_key",
values_to = "era_value",
cols = c(small, medium, large))
ggplot(era_compare, aes(x=date,
y = era_value,
color = era_key)) +
geom_line() +
theme_bw() +
labs(x="Date", y="Revenue") +
scale_color_discrete(name = "Exponential Rolling Average")
month <- format(purchase$date[1], "%Y-%m")
revenue_daily$date.month <- format(revenue_daily$date, "%Y-%m")
revenue_daily_group <- revenue_daily %>%
group_by(device, gender) %>%
summarise(revenue = mean(sum.revenue))
revenue$date.month <- format(revenue$date, "%Y-%m")
revenue$date.month <- format(revenue$date, "%Y-%m")
revenue_group <- revenue %>%
group_by(date.month, device, gender) %>%
summarise(revenue = mean(revenue))
revenue$date.month <- format(revenue$date, "%Y-%m")
revenue_group <- revenue %>%
group_by(date.month, device, gender) %>%
summarise(revenue = sum(revenue)) %>%
kable(col.names = c("Month","Device","Gender","Revenue"))
revenue_group
abtesting %>%
group_by(group) %>%
summarise(n()) %>%
ungroup()
